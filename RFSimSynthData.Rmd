---
title: "KNN simulation synthetic data"
author: "Thomas Devilee"
date: "9-5-2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(foreach)
library(tidyverse)
library(doParallel)
library(randomForest)
library(globaltest)
registerDoParallel(cores = 4)
source("sampling_funcs.R")
source("aux_funcs.R")
load("wsRFSynthData.RData")
set.seed(1979418)
```

### Randomforest code

```{r}
randomsplit <- function(regs, indx, spltb_reg, nodesize, leafsize = 1){
  unq_indx <- names(spltb_reg)
  splt_indx <- rep(NA, nrow(regs))
  
  for (i in 1:length(unq_indx)){
    sub_indx <- indx == unq_indx[i]
    sub_regs <- regs[sub_indx, ]
    n_sub <- sum(as.numeric(sub_indx))
    if(n_sub < 2*leafsize | all(!spltb_reg[[unq_indx[i]]]) | n_sub < nodesize) next
    splt <- TRUE
    while(splt){
      splt_indx[sub_indx] <- 1
      rcol <- sample(seq(1,ncol(regs)), size = 1)
      if (!rcol %in% which(spltb_reg[[unq_indx[i]]])) next
      rrow <- sample(1:nrow(sub_regs), size = 1)
      ineq_vec <- parse(text = paste(sub_regs[rrow, rcol], sample(c("<", "<=", ">=", ">"), size = 1), sub_regs[, rcol]))
      cond_indx <- sapply(ineq_vec, eval)
      splt_indx[sub_indx][cond_indx] <- 2
      if (var(splt_indx[sub_indx]) != 0) splt <- FALSE
    }
  }
  return(as.character(splt_indx))
}

updatesplit <- function(regs, indx, spltb_reg, nodesize, leafsize){
  out <- indx
  updt_indx <- randomsplit(regs = regs, indx = indx, spltb_reg = spltb_reg, nodesize = nodesize, leafsize = leafsize)
  log_indx <- !is.na(updt_indx)
  out[log_indx] <- paste0(indx[log_indx], updt_indx[log_indx])
  return(out)
}

regsplits <- function(regs, indx, leafsize){
  indx_names <- unique(indx)
  out <- vector(mode = "list", length = length(indx_names))
  names(out) <- indx_names
  
  for (i in 1:length(indx_names)){
    regs_sub <- regs[(indx == indx_names[i]), ]
    tmp <- vector(mode = "list", length = ncol(regs))
    
    for (j in 1:ncol(regs)){
      cumtable <- table(regs[, j])
      tmp[[j]] <- (sum(cumtable) - max(cumtable)) >= leafsize
    }
    
    out[[indx_names[i]]] <- drop(do.call(rbind, tmp))
    
  }
  return(out)
}

gensplits <- function(regs, maxdepth = NA, maxnodes = NA, nodesize = NA, leafsize = 1){
  if (is.na(maxnodes)) maxnodes <- nrow(regs)
  if (is.na(maxdepth)) maxdepth <- nrow(regs)
  if (is.na(nodesize)) nodesize <- 2
  indx <- rep("1", nrow(regs))
  out <- t(matrix(indx))
  out <- rbind(out, out)
  
  i <- 1
  spltb_reg <- regsplits(regs, out[i, ], leafsize = leafsize)
  psbl_split <- any(unlist(spltb_reg))
  while (max(nchar(out[i, ])) - 1 < maxdepth &
         length(unique(out[i, ])) < maxnodes &
         !all(table(out[i, ]) < 2*leafsize) &
         any(table(out[i, ] >= nodesize)) &
         psbl_split
         ){
    tmp <- updatesplit(regs = regs, indx = out[i, ], spltb_reg = spltb_reg, nodesize = nodesize, leafsize = leafsize)
    
    if(max(nchar(tmp)) - 1 <= maxdepth &
       length(unique(tmp)) <= maxnodes &
       all(table(tmp) >= leafsize)){
      
      out[i + 1, ] <- tmp
      i <- i + 1
      out <- rbind(out[1:i, ], out[i, ])
      spltb_reg <- regsplits(regs, out[i, ], leafsize = leafsize)
      psbl_split <- any(unlist(spltb_reg))
    }
  }
  return(out[i, ])
}

gentrees <- function(regs, n_tree, maxdepth = NA, maxnodes = NA, nodesize = NA, leafsize = 1){
  pckgs <- as.vector(lsf.str(.GlobalEnv))
  out <- foreach(j = 1:n_tree, .combine = "cbind", .export = pckgs) %dopar% {
    splts <- gensplits(regs = regs, maxdepth = maxdepth, maxnodes = maxnodes, nodesize = nodesize, leafsize = leafsize)
    sapply(splts, FUN = function(x) as.numeric(substr(x, nchar(x), nchar(x)) == 2))
  }
  out <- as.matrix(out)
  rownames(out) <- NULL
  colnames(out) <- 1:n_tree
  return(out)
}

randomRF <- function(regs, y, y_perm, n_tree, maxdepth = NA, maxnodes = NA, nodesize = NA, leafsize = 1){
  X <- gentrees(regs = regs, n_tree = n_tree, leafsize = leafsize, maxdepth = maxdepth, maxnodes = maxnodes, nodesize = nodesize)
  S_t <- S(X, y)
  S_p <- c(Inf, S(X, y_perm))
  out <- mean(S_t*(1-1e-14) <= S_p)
  return(out)
}

S <- function(X, y){
  Z <- matrix(1, nrow = nrow(X))
  X <- X - Z %*% solve(crossprod(Z), crossprod(Z, X))
  tmp <- crossprod(X, y)^2
  out <- apply(tmp, 2, sum)
  return(drop(out))
}
```


### Stability experiment

```{r}
StabExp <- function(n_tree, data, n_reps = 100, n_perms = 1000, leafsize = 5, maxdepth = NA, maxnodes = NA, nodesize = NA){
  pckgs <- as.vector(lsf.str(.GlobalEnv))
  labs <- data[, "y", drop = FALSE] ### extract labels
  regs <- data[, !names(data) %in% "y"] ### extract predictors
  y <- matrix(residuals(lm(y ~ 1, data = labs)), nrow = nrow(labs))
  
  out <- 
    foreach(i = 1:n_reps, .combine = "rbind", .packages = "foreach", .export = pckgs) %dopar% {
      y_perm <- sapply(1:(n_perms - 1), function(x, y) y[sample(nrow(y)), ,drop = FALSE], y = y)
      foreach (j = 1:length(n_tree), .combine = "c", .export = pckgs) %do% {
        randomRF(regs = regs, y = y, y_perm = y_perm, n_tree = n_tree[j], leafsize = leafsize, maxdepth = maxdepth,
                 maxnodes = maxnodes, nodesize = nodesize)
      }
    }
  out <- data.frame(out, row.names = NULL)
  colnames(out) <- n_tree
  return(out)
}
```

```{r}
tmp <- replicate(1000, expr = {
LDA20 <- LDASamp(n_samples = 20, p = 2, effect = 3.75)
gt(y ~ 1, y ~ ., data = LDA20)@result[1]})
mean(tmp <= 0.05)
```



```{r}
n_tree <- c(50, 100, 250, 500, 1000, 2500, 5000, 10000)
set.seed(1979418)
LDAdata <- LDASamp(n_samples = 20, p = 2, effect = 3.4)
StabLDA <- StabExp(n_tree = n_tree, data = LDAdata, n_reps = 100, leafsize = 3)
EmpericalPower(StabLDA)
```

```{r}
LDA40 <- LDASamp(n_samples = 40, p = 2, effect = 25)
StabLDA40 <- StabExp(n_tree = n_tree, data = LDA40, n_reps = 100, leafsize = 3)
```

```{r}
LDA80 <- LDASamp(n_samples = 80, p = 2, effect = 25)
StabLDA80 <- StabExp(n_tree = n_tree, data = LDA80, n_reps = 10, leafsize = 3)
```

```{r}
set.seed(1979418)
CSdata <- CheckerSamp(n = 3, n_clusts = 3)
StabCS <- StabExp(n_tree = n_tree, data = CSdata, n_reps = 100, leafsize = 3)
EmpericalPower(StabCS)
```

```{r}
CS3 <- CheckerSamp(n = 3, n_clusts = 3)
StabCS3 <- StabExp(n_tree = n_tree, data = CS3, n_reps = 100, leafsize = 2)
```

```{r}
CS6 <- CheckerSamp(n = 6, n_clusts = 3)
StabCS6 <- StabExp(n_tree = n_tree, data = CS6, n_reps = 100, leafsize = 2)
```

```{r}
powerplot <- function(..., x_names = NA, xlab = NA, sampsize = NA, alpha = 0.05){
  data <- list(...)
  if(all(is.na(x_names))) x_names <- 1:length(data)
  if(all(is.na(sampsize))) sampsize <- NULL
  data_long <- vector(mode = "list", length = length(data))
  for (i in 1:length(data)){
    tmp <- apply(data[[i]], 2,  function(x, alpha) mean(x < alpha), alpha = alpha)
    data_long[[i]] <- cbind(i, unlist(tmp), x_names)
  }
  data_long <- do.call(rbind.data.frame, data_long)
  colnames(data_long) <- c("exp", "power", "var")
  out <- ggplot(data = data_long, aes(x = var, y = power, colour = factor(exp))) + geom_line(linetype = "dashed") + geom_point() + 
    ylim(c(0, 1)) + xlab(xlab) + ylab("Power") + scale_color_discrete(name = "Sample size", labels = sampsize)
  return(out)
}
```

```{r}
powerplot(StabLDA20, StabLDA40, StabLDA80, x_names = n_tree, xlab = "Number of trees", sampsize = c(20, 40, 80))
```

```{r}
powerplot(StabCS3, StabCS6, x_names = c(50, 100, 250, 500, 1000), xlab = "Number of trees", sampsize = c(20, 40))
```

### Tree depth experiment

```{r}
PowerExp <- function(mthd = "LDA", n_reps = 100, n_perms = 1000, n_tree = 250, leafsize = 1, maxdepth = NA, maxnodes = NA, nodesize = NA, ...){
  indx_args <- c(length(n_tree) > 1, length(leafsize) > 1, length(maxdepth) > 1, length(maxnodes) > 1, length(nodesize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("n_tree", "leafsize", "maxdepth", "maxnodes", "nodesize")[indx_args]
  params <- cbind(n_tree, leafsize, maxdepth, maxnodes, nodesize)
  pckgs <- as.vector(lsf.str(.GlobalEnv))
  samp_ops <- list(...)
  if(mthd == "LDA"){
    data <- lapply(1:n_reps, FUN = function(x, sampsize, p, effect) LDASamp(n_samples = sampsize, p = p,
                   effect = effect), sampsize = samp_ops[["sampsize"]], p = samp_ops[["p"]], effect = samp_ops[["effect"]])
  } else if(mthd == "CS"){
     data <- lapply(1:n_reps, FUN = function(x, n_obs_clust, n_clusts) CheckerSamp(n = n_obs_clust, n_clusts = n_clusts),
                   n_obs_clust = samp_ops[["n_obs_clust"]], n_clusts = samp_ops[["n_clusts"]])
  } else {stop("No sampling method specified")}
  out <- 
    foreach(i = 1:n_reps, .combine = "rbind", .packages = "foreach", .export = pckgs) %dopar% {
      data_sub <- data[[i]]
      labs <- data_sub[, "y", drop = FALSE] ### extract labels
      regs <- data_sub[, !names(data_sub) %in% "y"] ### extract predictors
      y <- matrix(residuals(lm(y ~ 1, data = labs)), nrow = nrow(labs))
      y_perm <- sapply(1:(n_perms - 1), function(x, y) y[sample(nrow(y)), ,drop = FALSE], y = y)
      foreach (j = 1:nrow(params), .combine = "c", .export = pckgs) %do% {
        randomRF(regs = regs, y = y, y_perm = y_perm, params[[j, "n_tree"]], leafsize = params[[j, "leafsize"]],
                 maxdepth = params[[j, "maxdepth"]], maxnodes = params[[j, "maxnodes"]], nodesize = params[[j, "nodesize"]])
      }
    }
  out <- data.frame(out, row.names = NULL)
  colnames(out) <- eval(parse(text = var_name))
  return(out)
}
```


```{r}
set.seed(1979418)
LDAs_depth <- PowerExp(mthd = "LDA", sampsize = 20, effect = 5, p = 2, n_reps = 100, maxdepth  = c(seq(1, 10), 15, 10, 20))
```

```{r}
powerplot(LDAs_depth, x_names = c(seq(1, 10), 15, 10, 20), xlab = "Maximum tree depth", sampsize = 20)
```

```{r}
set.seed(1979418)
LDAs_leaf5 <- PowerExp(mthd = "LDA", sampsize = 20, effect = 5, p = 2, n_reps = 100, leafsize = 5)
```


```{r}
set.seed(1979418)
CS_depth <- PowerExp(mthd = "CS", n_obs_clust = 15, n_clusts = 3, n_reps = 100, maxdepth = c(seq(1, 10), 15, 25, 50, 80, 135))
```

```{r}
powerplot(CS_depth, x_names = c(seq(1, 10), 15, 25, 50, 80, 135), xlab = "Maximum tree depth", sampsize = 135)
```

```{r}
set.seed(1979418)
CS_leaf5 <- PowerExp(mthd = "CS", n_obs_clust = 15, n_clusts = 3, n_reps = 100, leafsize = 5)
```



### Simulation experiment

```{r}
### function to compute linear global test
linear.gt <- function(regs, labs){
  res <- gt(y~1, y~., data = data.frame(regs, y = labs)) ### linear global test
  return(res@result[1])  ### return p-value
}
```

```{r}
### function to compute perform nested ridge
nestedcv.ridge <- function(folds, regs, labs){
  regs <- apply(regs, 2, as.numeric) ### makes sure all columns are numeric
  n_folds <- max(folds) ### number of folds
  res_outer <- numeric(n_folds) ### initialize output 
  for(i in 1:n_folds){ 
    log_indx <- folds != i ### create logical index for subset of the data
    regs_sub <- as.matrix(regs[log_indx, ]) ### select regressor and put in right format
    labs_sub <- labs[log_indx, , drop = TRUE] ### select labels
    folds_sub <- rename_folds(folds[log_indx]) ### rename folds to 1, ... k - 1 (required for cv.glment)
    res_cv <- glmnet::cv.glmnet(x = regs_sub, y = labs_sub, type.measure = "mse", foldid = folds_sub, alpha = 0) ### compute optimal lambda
    preds <- predict(res_cv, as.matrix(regs[folds == i,]), s = "lambda.min") >= 0.5 ### make predictions for the validation set from a model with the optimal lambda
    res_outer[i] <- mean(preds == labs[folds == i, , drop = TRUE]) ### compute average accuracy on outer validation set
  }
  return(mean(res_outer))
}
```

```{r}
nestedcv.rf <- function(folds, regs, labs, mtry = c("p", "p/3", "sqrt(p)"), nodesize = c(5, 1), n_tree = c(100, 250, 500)){
  p <- ncol(regs)
  mtry <- sapply(mtry, function(x, p) eval(parse(text = x)), p = p)
  mtry <- unique(round(mtry))
  if (length(mtry > 2)) mtry <- mtry[-1]
  grid_params <- expand.grid(mtry = sapply(mtry, function(x, p) eval(parse(text = x)), p = p),
                            nodesize = nodesize,
                            ntree = n_tree)

  n_folds <- max(folds) ### total number of folds
  res_outer <- numeric(n_folds) ### initialize outerloop output
  fold_id <- seq(1, n_folds) ### create fold numbers for innerloop
  for(i in 1:n_folds){  ### for all folds
    res_inner <- matrix(NA, nrow = n_folds - 1, ncol = nrow(grid_params)) ### initialize innerloop output matrix
    for(j in 1:(n_folds - 1)){ ### for all folds - 1 (excluding one outer validations set)
      for(k in 1:nrow(grid_params)){ ### for every neighbour
        indx <- fold_id[fold_id != i]  ### exclude outer validation set
        tmp <- randomForest::randomForest(x = regs[(folds %in% indx[-j]),],  y = labs[(folds %in% indx[-j]), ],
                                          xtest = regs[(folds == indx[j]),], ytest = labs[folds == indx[j], ],
                                          mtry = grid_params[[k, "mtry"]], nodesize = grid_params[[k, "nodesize"]],
                                          ntree = grid_params[[k, "ntree"]]) ### train on n_folds - 2
        res_inner[j, k] <- mean(tmp[["test"]][["predicted"]] != labs[folds == indx[j], ]) ### validate on innerloop validation set
      }
    }
    res_inner <- apply(res_inner, MARGIN = 2, mean) ### compute average misclassification rate over the innerloop folds
    opt_params <- grid_params[which.min(res_inner), ]
    preds <- randomForest::randomForest(x = regs[folds != i,],  y = labs[folds != i, ],
                                        xtest = regs[folds == i,], ytest = labs[folds == i, ],
                                        mtry = opt_params[["mtry"]], nodesize = opt_params[["nodesize"]],
                                        ntree = opt_params [["ntree"]])[["test"]][["predicted"]]
    res_outer[i] <- mean(as.numeric(preds >= 0.5) == labs[folds == i, ])  ### compute average accuracy on outer validation set
  }
  return(mean(res_outer))
}
```

```{r}
pval.rf_gt <- function(regs, labs, maxdepth = NA, n_perms = 1000, n_tree = 250, balanced = TRUE, force = FALSE, leafsize = 1, maxnodes = NA, nodesize = NA){
  i <- 1 ### arbitrarily choose a validation fold
  folds <- create_folds(n_folds = 2, labs = labs, balanced = balanced, force = force) ### create folds such that the groups are balanced
  indx_train <- folds != i
  n_train <- sum(folds != i) ### compute the number of observations in each folds
  if (all(is.na(maxdepth))) maxdepth <- unique(c(seq(1, 5), round(seq(5, n_train/2, length.out = round(sqrt(n_train))))))
  y_train <- matrix(as.numeric(labs[indx_train, ]))
  p_vals <- numeric(length(maxdepth)) ### initialize vector for p-values
  
  y_perm_train <- sapply(1:(n_perms - 1), function(x, y) y[sample(nrow(y)), ,drop = FALSE], y = y_train)
  for (i in 1:length(maxdepth)){
    p_vals[i] <- randomRF(regs = regs[indx_train, ], y = y_train, y_perm = y_perm_train, n_tree = n_tree, leafsize = leafsize, 
                          maxdepth = maxdepth[i], maxnodes = maxnodes, nodesize = nodesize)

  }
  
  optimal_depth <- maxdepth[which.min(p_vals)] ### select k which corresponds to smallest p-value
  y_test <- matrix(as.numeric(labs[!indx_train, ]))
  y_perm_test <- sapply(1:(n_perms - 1), function(x, y) y[sample(nrow(y)), ,drop = FALSE], y = y_test)
  res <- randomRF(regs = regs[!indx_train, ], y = y_test, y_perm = y_perm_test, n_tree = n_tree, leafsize = leafsize, 
                          maxdepth = optimal_depth, maxnodes = maxnodes, nodesize = nodesize)
  return(res)
}
```

```{r}
overall.Sgt <- function(regs, labs, n_tree = 250, maxdepth = NA, n_perms = 1000, leafsize = 1, maxnodes = NA, nodesize = NA){
  pckgs <- as.vector(lsf.str(.GlobalEnv))
  n <- nrow(regs)
  y <- matrix(as.numeric(labs[["y"]]))
  y_perm <- sapply(1:(n_perms - 1), function(x, y) y[sample(nrow(y)), ,drop = FALSE], y = y)
  X <- gentrees(regs = regs, n_tree = 1, leafsize = leafsize, maxdepth = ceiling(runif(1, min = 0, max = 5)), maxnodes = maxnodes, nodesize = nodesize)
  for(i in 1:(n_tree-1)){
    X <- cbind(X, gentrees(regs = regs, n_tree = 1, leafsize = leafsize, maxdepth = ceiling(runif(1, min = 0, max = 5)), maxnodes = maxnodes, nodesize = nodesize))
  }
  S_t <- S(X, y)
  S_p <- c(Inf, S(X, y_perm))
  out <- mean(S_t*(1-1e-14) <= S_p)
  return(out)
}
```


```{r}
SimExp <- function(data, n_reps, indx = NA, n_perms = 100, ...){
  pckgs <- as.vector(lsf.str(.GlobalEnv))
  labs <- data[, "y", drop = FALSE] ### extract labels
  regs <- data[, !names(data) %in% "y"] ### extract predictors
  if(all(is.na(indx))){ ### if no index specified
    indx <- create_folds(n_folds = n_reps, labs = labs, ...) ### compute folds equal to the number of replications
  }
  res <- matrix(data = NA, nrow = n_reps, ncol = 5) ### initialize output matrix
  colnames(res) <- c("linear.gt", "nestedcv.ridge", "nestedcv.rf", "pval.rf_gt", "overall.Sgt") ### assign names to the output matrix
  
  for(i in 1:max(indx)){ ### for each folds
    sub_regs <- regs[indx == i,] ### select regressor subset
    sub_labs <- labs[indx == i, , drop = FALSE] ### select label subset
    folds <- create_folds(n_folds = 5, labs = sub_labs, ...) ### create folds for functions that require cross validation
    res[i, 1] <- linear.gt(regs = sub_regs, labs = sub_labs) ### compute p-value of the linear global test
    ridge_stat <- nestedcv.ridge(folds = folds, regs = sub_regs, labs = sub_labs) ### compute test statistic for the nested ridge
    rf_stat <- nestedcv.rf(folds = folds, regs = sub_regs, labs = sub_labs) ### compute test statistic for the nested knn
    res[i, 4] <- pval.rf_gt(regs = sub_regs, labs = sub_labs, ...)
    res[i, 5] <- overall.Sgt(regs = sub_regs, labs = sub_labs)
    
    perm_mat <- foreach(j = 1:(n_perms-1), .combine = "cbind", .export = pckgs) %dopar% { ### for n_perms replications
      perm_indx <- sample(nrow(sub_labs)) ### permutation index
      perm_regs <- sub_regs[perm_indx, ] ### permute regressors
      perm_folds <- create_folds(n_folds = 5, labs = sub_labs, ...) ### compute folds
      perm_ridge <- nestedcv.ridge(folds = perm_folds, regs = perm_regs, labs = sub_labs) ### compute (permuted) test statistic for the nested ridge
      perm_rf <- nestedcv.rf(folds = perm_folds, regs = perm_regs, labs = sub_labs) ### compute (permuted) test statistic for the nested knn
      matrix(c(perm_ridge, perm_rf), nrow = 2) ### return permuted test statistics for both tests
    }
    res[i, 2] <- mean(ridge_stat*(1-1e-14) <= c(Inf, perm_mat[1, , drop = TRUE])) ### compute emperical p-value for nested ridge
    res[i, 3] <- mean(rf_stat*(1-1e-14) <= c(Inf, perm_mat[2, , drop = TRUE])) ### compute emperical p-value for nested knn
  }
  return(res)
}
```


```{r}
LDASim <- function(sampsize, n_reps, effect, p, n_perms = 1000, n_tree = 250, leafsize = 1, maxdepth = NA, maxnodes = NA, nodesize = NA, ...){
  indx_args <- c(length(p) > 1, length(effect) > 1, length(sampsize) > 1, length(n_tree) > 1, length(leafsize) > 1, length(maxdepth) > 1, length(maxnodes) > 1, length(nodesize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("p", "effect", "sampsize", "n_tree", "leafsize", "maxdepth", "maxnodes", "nodesize")[indx_args]
  params <- cbind(p, effect, sampsize, n_tree, leafsize, maxdepth, maxnodes, nodesize) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    data <- LDASamp(n_samples = params[i, "sampsize"] * n_reps, p = params[i, "p"], effect = params[i, "effect"])
    tmp <- SimExp(n_reps = n_reps, data = data, indx = NA, n_tree = params[[i, "n_tree"]], n_perms = n_perms,
                  leafsize = params[[i, "leafsize"]], maxdepth = params[[i, "maxdepth"]],
                  maxnodes = params[[i, "maxnodes"]], nodesize = params[[i, "nodesize"]], ...)
    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  if(sum(as.numeric(indx_args)) > 0){
    x_names <- c("Dimensionality", "Effect", "Sample size", "Number of trees", "Leaf size", "Maximum tree-depth", "Maximum number of nodes", 
                 "Node size")
    out <- data.frame(out, params[, var_name])
    colnames(out)[ncol(out)] <- var_name
    out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
    out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point() + 
      ylim(c(0, 1)) + xlab(x_names[indx_args]) + ylab("Power") + scale_color_discrete(name = "Method")
  }
  return(out)
}
```


```{r}
CheckerSim <- function(n_reps, n, n_clusts, n_perms = 1000, n_tree = 250, leafsize = 1, maxdepth = NA, maxnodes = NA, nodesize = NA, ...){
  indx_args <- c(length(n) > 1, length(n_clusts) > 1, length(n_tree) > 1, length(leafsize) > 1, length(maxdepth) > 1, length(maxnodes) > 1, length(nodesize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("n", "n_clusts", "n_tree", "leafsize", "maxdepth", "maxnodes", "nodesize")[indx_args]
  params <- cbind(n, n_clusts, n_tree, leafsize, maxdepth, maxnodes, nodesize) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    sampsize <- params[[i, "n_clusts"]]^2 * params[[i, "n"]]
    indx <- as.vector(sapply(1:n_reps, function(x, sampsize) rep(x, sampsize), sampsize = sampsize))
    data <- lapply(1:n_reps, FUN = function(x, n, n_clusts) CheckerSamp(n = n, n_clusts = n_clusts),
                   n = params[[i, "n"]], n_clusts = params[[i, "n_clusts"]])
    data <- do.call(rbind, data)
    tmp <- SimExp(n_reps = n_reps, data = data, indx = indx, n_tree = params[[i, "n_tree"]], n_perms = n_perms,
                  leafsize = params[[i, "leafsize"]], maxdepth = params[[i, "maxdepth"]],
                  maxnodes = params[[i, "maxnodes"]], nodesize = params[[i, "nodesize"]], ...)

    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  if(sum(as.numeric(indx_args)) > 0){
    x_names <- c("Sample size", "Number of clusters", "Number of trees", "Leaf size", "Maximum tree-depth", "Maximum number of nodes", 
                 "Node size")
    out <- data.frame(out, params[, var_name])
    colnames(out)[ncol(out)] <- var_name
    out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
    out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point() + 
      ylim(c(0, 1)) + xlab(x_names[indx_args]) + ylab("Power") + scale_color_discrete(name = "Method")
  }
  return(out)
}
```
















```{r}
CheckerSim <- function(n_reps, n, n_clusts, ...){
  indx_args <- c(length(n) > 1, length(n_clusts) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("n", "n_clusts")[indx_args]
  params <- cbind(n, n_clusts) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    sampsize <- params[[i, "n_clusts"]]^2 * params[[i, "n"]]
    indx <- as.vector(sapply(1:n_reps, function(x, sampsize) rep(x, sampsize), sampsize = sampsize))
    data <- lapply(1:n_reps, FUN = function(x, n, n_clusts) CheckerSamp(n = n, n_clusts = n_clusts),
                   n = params[[i, "n"]], n_clusts = params[[i, "n_clusts"]])
    data <- do.call(rbind, data)
    tmp <- SimExp(n_reps = n_reps, data = data, indx = indx, ...)
    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  if(sum(as.numeric(indx_args)) > 0){
    x_names <- c("Sample size", "Number of clusters")
    out <- data.frame(out, params[, var_name])
    colnames(out)[ncol(out)] <- var_name
    out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
    out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point() +
      ylim(c(0, 1)) + xlab(x_names[indx_args]) + ylab("Power") + scale_color_discrete(name = "Method")
  }
  return(out)
}

CheckerSim(n_reps = 1, n = 3, n_clusts = c(3, 5), force = TRUE)
```

```{r}
LDASim <- function(sampsize, n_reps, effect, p, ...){
  indx_args <- c(length(p) > 1, length(effect) > 1, length(sampsize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("p", "effect", "sampsize")[indx_args]
  params <- cbind(p, effect, sampsize) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    data <- LDASamp(n_samples = params[i, "sampsize"] * n_reps, p = params[i, "p"], effect = params[i, "effect"])
    tmp <- SimExp(n_reps = n_reps, data = data, ...)
    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  if(sum(as.numeric(indx_args)) > 0){
    x_names <- c("Dimensionality", "Effect", "Sample size")
    out <- data.frame(out, params[, var_name])
    colnames(out)[ncol(out)] <- var_name
    out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
    out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point() + 
      ylim(c(0, 1)) + xlab(x_names[indx_args]) + ylab("Power") + scale_color_discrete(name = "Method")
  }
  return(out)
}
tmp <- LDASim(sampsize = 20, n_reps = 1, effect = 25, p = c(2, 3))
SimExp(tmp, 1, n_perms = 10, force = FALSE)
```


```{r}
regs <- LDA20[, !names(LDA20) %in% "y"]
labs <- LDA20[, "y", drop = FALSE]
folds <- create_folds(2, labs)
```





















```{r}
library(tree)
tmp <- tree(y ~ x1 + x2 ,data = LDA20, mincut = 1, minsize = 2)
plot(tmp)
text(tmp)

nestedcv.tree <- function(folds, regs, labs, leafsize = c(5, 1), split = c("deviance", "gini")){
  grid_params <- expand.grid(mincut = leafsize,
                            split = split)
  n_folds <- max(folds) ### total number of folds
  res_outer <- numeric(n_folds) ### initialize outerloop output
  fold_id <- seq(1, n_folds) ### create fold numbers for innerloop
  for(i in 1:n_folds){  ### for all folds
    res_inner <- matrix(NA, nrow = n_folds - 1, ncol = nrow(grid_params)) ### initialize innerloop output matrix
    for(j in 1:(n_folds - 1)){ ### for all folds - 1 (excluding one outer validations set)
      for(k in 1:nrow(grid_params)){ ### for every neighbour
        indx <- fold_id[fold_id != i]  ### exclude outer validation set
        tmp <- tree::tree(y ~ ., data = cbind.data.frame(labs[(folds %in% indx[-j]), , drop = FALSE], regs[(folds %in% indx[-j]),]), 
                          mincut = grid_params[[k, "mincut"]], minsize = 2*grid_params[[k, "mincut"]],
                          split = as.character(grid_params[[k, "split"]])) ### train on n_folds - 2
        
        res_inner[j, k] <- mean(predict(tmp, regs[(folds %in% indx[j]),]) != labs[folds == indx[j], ]) ### validate on innerloop validation set
      }
    }
    res_inner <- apply(res_inner, MARGIN = 2, mean) ### compute average misclassification rate over the innerloop folds
    opt_params <- grid_params[which.min(res_inner), ]
    model <- tree::tree(y ~ ., data = cbind.data.frame(labs[folds != i, , drop = FALSE], regs[folds != i,] ),
                        mincut = opt_params[["mincut"]], minsize = 2*opt_params[["mincut"]],
                        split = as.character(opt_params[["split"]]))
    preds <- predict(model, regs[folds == i,])
    res_outer[i] <- mean(preds == labs[folds == i, ])  ### compute average accuracy on outer validation set
  }
  return(mean(res_outer))
}
nestedcv.tree(folds, regs, labs)
```


```{r}
labs <- LDA20[, "y", drop = FALSE]
regs <- LDA20[,  !colnames(LDA20) %in% "y"]
folds <- create_folds(n_folds = 5, labs, balanced = TRUE, force = FALSE)
```

