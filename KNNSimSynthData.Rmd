---
title: "KNN simulation synthetic data"
author: "Thomas Devilee"
date: "06/04/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load data and packages
```{r}
library(parallel)
library(doParallel)
library(foreach)
numCores <- detectCores()
registerDoParallel(numCores)
library(readxl)
library(class)
library(globaltest)
library(ggplot2)
library(glmnet)
library(dplyr)
library(MASS)
library(gridExtra)
library(tidyr)
source("sampling_funcs.R")
load("wsKNNSynthData.RData")
set.seed(1979418)

### function to read excel files in the current directory in the format "sim_X.xlsx"
ReadData <- function(names){
  out <- vector(mode = "list", length = length(names)) ### initialize empty list with length equal to the number of datasets to be read (names)
  names(out) <- names ### assign list names
  for(i in 1:length(names)){ ### for all datasets to be read
    name <- paste0("sim_", names[i], ".xlsx")
    data <- read_excel(name) ### read excel files
    data <- data[order(data[["y"]]), ] ### order data based on y (label) value (small to big)
    data[["y"]] <- ifelse(data[["y"]] == 0, FALSE, TRUE) ### replace label values with FALSE if 0 and TRUE if 0
    out[[i]] <- data ### save this modified file to the list
  }
  return(out)
}
```

```{r}
data <- ReadData(c("linear", "moons", "circles"))
```

```{r}
### function to create folds implicitly requires the group size per class has to be equal
### if balanced is true (works only for two classes), the labels have to be sorted (low to high) 
create_folds <- function(n_folds, labs, balanced = TRUE, force = FALSE){
  if(balanced){
    if (any(order(as.numeric(labs[["y"]])) != seq(1, nrow(labs)))) stop("Data (labels) is not sorted") ### checks if the above requirments are met
    n1 <- nrow(labs) - sum(as.numeric(labs[["y"]]))
    n2 <- sum(as.numeric(labs[["y"]]))
    reps1 <- n1/n_folds
    reps2 <- n2/n_folds
    if ((!is.int(reps1) | !is.int(reps2)) & !force) stop("Cannot balance folds")
    folds1 <- rep(seq(1, n_folds), ceiling(reps1))[1:n1] ### create n fold indexes for group 1
    folds2 <- rep(seq(1, n_folds), ceiling(reps2))[1:n2] ### create n fold indexes for group 2
    folds <- c(sample(folds1), sample(folds2)) ### randomly assign indexes to each observation in a balanced fashion
  } else{
    folds <- sample(rep(seq(1, n_folds), nrow(labs)/n_folds)) ### randomly assign folds if balanced is false
  }
  return(folds)
}

comp_dist <- function(x, method = "euclidian", scale = FALSE){
  if(scale == TRUE) x <- scale(x)
  if(method == "euclidian") out <- as.matrix(dist(x, diag = TRUE, upper = TRUE))
  if(method == "cor") out <- 1 - as.matrix(cor(t(x), method = "pearson"))
  return(out)
} 

### function to compute knn ordering matrix for a given distance matrix
knn_mat <- function(dist_mat){
  n <- nrow(dist_mat) ### number of observations
  nn <- (n + 1) - t(apply(dist_mat, MARGIN = 1, FUN = rank)) ### ordering distance per observation
  return(nn)
}

rename_folds <- function(folds){
  digits <- sort(unique(folds)) ### sort all unique fold ids
  for (i in 1:length(digits)){ ### for each element in unique sorted folds
    folds[folds == digits[i]] <- i ### rename to 1, .., k (k = length(unique sorted folds))
  }
  return(folds) 
}

InvPropWeight <- function(P, y){
  data <- data.frame(P, y = y)
  Z <- model.matrix(y ~ 1, data = data)
  X <- model.matrix(y ~ 0 + ., data = data)
  m <- ncol(Z)
  n <- nrow(Z)
  y <- residuals(lm(y ~ 1, data = data))
  sumyy <- sum(y*y)
  X <- X - Z %*% solve(crossprod(Z), crossprod(Z, X))
  csm <- colSums(X*X)
  X[,csm < max(csm)*1e-14] <- 0
  xy <- crossprod(X, y)
  S <- sum(xy * xy) / sumyy
  if (sumyy == 0) S <- 0
  lams <- eigen(crossprod(X), symmetric = TRUE, only.values=TRUE)$values
  if (length(lams) < n) lams <- c(lams, numeric(n-length(lams)))
  lams[1:(n-m)] <- lams[1:(n-m)] - S
  tr.term <- crossprod(X)
  var.num <- 2*sum(tr.term*tr.term)
  mu.num <- sum(lams) + (n-m)*S
  mu.den <- n-m
  var.den <- 2*(n-m)
  cov.term <- 2*mu.num
  VarS <- (mu.num^2/mu.den^2) * (var.num/(mu.num^2)  + var.den/(mu.den^2) - 2*cov.term/(mu.num*mu.den))
  weight <- 1/sqrt(VarS)
  if (is.nan(weight) | weight > 10^6) weight <- 0
  return(weight)
}

XXT <- function(ord_mat, weights = NA){
  weighting <- TRUE ### weighting true by default
  k <- dim(ord_mat)[1] ### number of observations/partition matrices
  if(all(is.na(weights))){ ### if no weights specified
    weighting <- FALSE ### set weighting to FALSE
    weights <- rep(1, k) ### set al weights to 1
  }
  if(weighting & k != length(weights)) stop("Incorrect dimensions weights") ### check if the dimensions of the weights match the number of partition matrices
  
  weights <- cumsum(rev(weights)^2) ### compute cumulative squared weights
  out <- matrix(data = NA, nrow = k, ncol = k) ### initialize output matrix
  diag(out) <- sum(weights) ### compute diagonal
  for(i in 1:(k - 1)){ ### compute all elements in the upper triangle (without diagonal) of the output matrix
    for(j in (i + 1):k){
      out[i, j] <- sum(weights[pmin(ord_mat[i,], ord_mat[j,])])
    }
  }
  out[lower.tri(out)] <- t(out)[lower.tri(out)] ### reflect upper triangle onto lower triangle
  return(out)
}

is.int <- function(x) x%%1 == 0

EmpericalPower <- function(data){
  out <- apply(data, 2, function(x) mean(x < 0.05))
  return(out)
}
```

```{r}
### All functions below require specification of  the regressors (regs) as data frame and label (labs) as data frame. Some functions also require the fold id (folds) as vector

### function to performed nested knn based on a specified number of neighbours
nestedcv.knn <- function(folds, regs, labs){
  n_folds <- max(folds) ### total number of folds
  res_outer <- numeric(n_folds) ### initialize outerloop output
  fold_id <- seq(1, n_folds) ### create fold numbers for innerloop
  n_trin <- (n_folds - 2)*min(table(folds))[[1]]
  neighbours <- round(seq(1, n_trin, length.out = round(sqrt(n_trin))))
  for(i in 1:n_folds){  ### for all folds
    res_inner <- matrix(NA, nrow = n_folds - 1, ncol = length(neighbours)) ### initialize innerloop output matrix
    for(j in 1:(n_folds - 1)){ ### for all folds - 1 (excluding one outer validations set)
      for(k in 1:length(neighbours)){ ### for every neighbour
        indx <- fold_id[fold_id != i]  ### exclude outer validation set
        tmp <- class::knn(regs[(folds %in% indx[-j]),], regs[(folds == indx[j]),], labs[(folds %in% indx[-j]), , drop = TRUE], k = neighbours[k]) ### train on n_folds - 2
        res_inner[j, k] <- mean(tmp != labs[folds == indx[j], , drop = TRUE]) ### validate on innerloop validation set
      }
    }
    res_inner <- apply(res_inner, MARGIN = 2, mean) ### compute average misclassification rate over the innerloop folds
    optimal_k <- neighbours[which.min(res_inner)]
    preds <- class::knn(regs[folds != i,], regs[folds == i,], labs[folds != i, , drop = TRUE], k = optimal_k) ### train on n_folds - 1 for the k with the smallest misclassification rate
    res_outer[i] <- mean(preds == labs[folds == i, , drop = TRUE])  ### compute average accuracy on outer validation set
  }
  return(mean(res_outer))
}
### function to compute perform nested ridge
nestedcv.ridge <- function(folds, regs, labs){
  regs <- apply(regs, 2, as.numeric) ### makes sure all columns are numeric
  n_folds <- max(folds) ### number of folds
  res_outer <- numeric(n_folds) ### initialize output 
  for(i in 1:n_folds){ 
    log_indx <- folds != i ### create logical index for subset of the data
    regs_sub <- as.matrix(regs[log_indx, ]) ### select regressor and put in right format
    labs_sub <- labs[log_indx, , drop = TRUE] ### select labels
    folds_sub <- rename_folds(folds[log_indx]) ### rename folds to 1, ... k - 1 (required for cv.glment)
    res_cv <- glmnet::cv.glmnet(x = regs_sub, y = labs_sub, type.measure = "mse", foldid = folds_sub, alpha = 0) ### compute optimal lambda
    preds <- predict(res_cv, as.matrix(regs[folds == i,]), s = "lambda.min") >= 0.5 ### make predictions for the validation set from a model with the optimal lambda
    res_outer[i] <- mean(preds == labs[folds == i, , drop = TRUE]) ### compute average accuracy on outer validation set
  }
  return(mean(res_outer))
}
### function to compute linear global test
linear.gt <- function(regs, labs){
  res <- gt(y~1, y~., data = data.frame(regs, y = labs)) ### linear global test
  return(res@result[1])  ### return p-value
}

```

```{r}
### function to perform unweighted and inverse weighted overall global test
overall.gt <- function(regs, labs, invweighted = FALSE){
  n <- nrow(regs) ### compute number of observations
  dist_mat <- comp_dist(regs) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering matrix
  weights <- numeric(n) ### initialize weight vector
  if (invweighted){ ### if inverse weights
    for(i in 1:n){ ### for all 1, ..., k neighbours
      P <- ifelse(ord_mat > (n - i), 1, 0) ### compute partition matrix
      weights[i] <- InvPropWeight(P, labs) ### weight according to inverse of variance of partition matrix
    }
  }
  X <- t(chol(XXT(ord_mat = ord_mat))) ### perform cholesky decomosition on XXT to increase computation performance
  res <- globaltest::gt(y ~ 1, y ~ ., data = data.frame(X, y = labs))@result[1] ### perform global test on cholesky decomposition
  if(invweighted){ ### if inverse weights
    X_iw <- t(chol(XXT(ord_mat = ord_mat, weights = weights))) ### perform cholesky decomosition on weighted XXT to increase computation performance
    res <- cbind(res, globaltest::gt(y ~ 1, y ~ ., data = data.frame(X_iw, y = labs))@result[1]) #### perform global test on inversely weighted partition matrices
  }
  return(res)
}
```


```{r}
### function to perform global test on a partition matrix which corresponds to the (smallest) fraction of labels times the number of observations (rounded)
prop.knn_gt <- function(regs, labs){
  prop <- mean(labs[["y"]]) ### compute fraction of labels
  prop <- min(prop, 1 - prop) ### select the smallest fraction
  dist_mat <- comp_dist(regs) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering mat
  P <- ifelse(ord_mat > nrow(regs) - prop*nrow(regs), 1, 0) ### compute partition matrix corresponding to the smallest fraction of labels
  res <- gt(y ~ 1, y ~ ., data = cbind(P, labs))@result[1] ### compute gt statistic based on partition matrix
  return(res)
}

### function to perform the global test on the partition matrix of the validation set for the value of k which corresponds to the smallest p-value in the training set (splits data in two)
pval.knn_gt <- function(regs, labs, balanced = TRUE, force = FALSE){
  i <- 1 ### arbitrarily choose a validation fold
  folds <- create_folds(n_folds = 2, labs = labs, balanced = balanced, force = force) ### create folds such that the groups are balanced
  n_train <- sum(folds != i) ### compute the number of observations in each folds
  neighbours <- round(seq(2, n_train - 1, length.out = round(sqrt(n_train))))
  dist_mat <- comp_dist(regs[folds != i, ]) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering mat
  p_vals <- numeric(length(neighbours)) ### initialize vector for p-values
  for (j in 1:length(neighbours)){ ### for all 2, ..., k neighbours
    P <- ifelse(ord_mat > (n_train - neighbours[j]), 1, 0) ### compute partition matrix and save in list
    p_vals[j] <- log(globaltest::gt(y ~ 1, y ~ ., data = cbind(P, labs[folds != i, ]))@result[1]) ### compute gt statistic based on partition matrix
    }
    optimal_k <- neighbours[which.min(p_vals)] ### select k which corresponds to smallest p-value
    n_test <- sum(folds == i) ### compute number of observations in validation set
    dist_mat <- comp_dist(regs[folds == i, ]) ### compute distance matrix
    ord_mat <- knn_mat(dist_mat) ### compute ordering mat
    P <- ifelse(ord_mat > (n_test - optimal_k), 1, 0) ### compute partition matrix for optimal k
    res <- gt(y ~ 1, y ~ ., data = cbind(P, labs[folds == i, ]))@result[1] ### perform global test
  return(res)
}

overall.gt <- function(regs, labs, invweighted = FALSE){
  n <- nrow(regs) ### compute number of observations
  dist_mat <- comp_dist(regs) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering matrix
  P <- P_iw <- vector(mode = "list", length = n)
  for(i in 1:n){ ### for all 1, ..., k neighbours
    P[[i]] <- ifelse(ord_mat > (n - i), 1, 0) ### compute partition matrix
    if(invweighted){
      weight <- InvPropWeight(P[[i]], labs) ### weight according to inverse of variance of partition matrix
      P_iw[[i]] <- P[[i]] * weight
    }
  }
  X <- do.call(cbind, P)
  res <- globaltest::gt(y ~ 1, y ~ ., data = data.frame(X, y = labs))@result[1] ### perform global test on cholesky decomposition
  if(invweighted){ ### if inverse weights
    X_iw <- do.call(cbind, P_iw) ### perform cholesky decomosition on weighted XXT to increase computation performance
    res <- cbind(res, globaltest::gt(y ~ 1, y ~ ., data = data.frame(X_iw, y = labs))@result[1]) #### perform global test on inversely weighted partition matrices
  }
  return(res)
}

overallordinal.gt <- function(regs, labs){
  dist_mat <- comp_dist(regs) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering matrix
  X  <- apply(ord_mat, 2, rank)
  res <- globaltest::gt(y ~ 1, y ~ ., data = data.frame(X, y = labs))@result[1]
  return(res)
}
```


```{r}
pckgs <- as.vector(lsf.str())
  
SimExp <- function(data, n_reps, pckgs, indx = NA, n_perms = 100, ...){
  labs <- data[, "y"] ### extract labels
  regs <- data[, !names(data) %in% "y"] ### extract predictors
  if(all(is.na(indx))){ ### if no weights specified
    indx <- create_folds(n_folds = n_reps, labs = labs, ...) ### compute folds equal to the number of replications
  }
  res <- matrix(data = NA, nrow = n_reps, ncol = 8) ### initialize output matrix
  colnames(res) <- c("linear.gt", "nestedcv.ridge", "nestedcv.knn", "prop.knn_gt", "pval.knn_gt", "overall.gt", "invoverall.gt", "overordinall.gt") ### assign names to the output matrix
  
  for(i in 1:max(indx)){ ### for each folds
    sub_regs <- regs[indx == i,] ### select regressor subset
    sub_labs <- labs[indx == i,] ### select label subset
    folds <- create_folds(n_folds = 5, labs = sub_labs, ...) ### create folds for functions that require cross validation
    res[i, 1] <- linear.gt(regs = sub_regs, labs = sub_labs) ### compute p-value of the linear global test
    ridge_stat <- nestedcv.ridge(folds = folds, regs = sub_regs, labs = sub_labs) ### compute test statistic for the nested ridge
    knn_stat <- nestedcv.knn(folds = folds, regs = sub_regs, labs = sub_labs) ### compute test statistic for the nested knn
    res[i, 4] <- prop.knn_gt(regs = sub_regs, labs = sub_labs) ### compute p-value for the global test on the partition matrix based on the label proportion
    res[i, 5] <- pval.knn_gt(regs = sub_regs, labs = sub_labs, ...) ### compute p-value for the global test based on the value of k which has the smallest p-value in the training set
    res[i, c(6, 7)] <- overall.gt(regs = sub_regs, labs = sub_labs, invweighted = TRUE) ### compute unweighted and inversely weighted overall gloval test
    res[i, 8] <- overallordinal.gt(regs = sub_regs, labs = sub_labs) ### compute unweighted and inversely weighted overall gloval test
    
    perm_mat <- foreach(j = 1:n_perms, .combine = "cbind", .export = pckgs) %dopar% { ### for n_perms replications
      perm_indx <- sample(nrow(sub_labs)) ### permutation index
      perm_regs <- sub_regs[perm_indx, ] ### permute regressors
      perm_folds <- create_folds(n_folds = 5, labs = sub_labs, ...) ### compute folds
      perm_ridge <- nestedcv.ridge(folds = perm_folds, regs = perm_regs, labs = sub_labs) ### compute (permuted) test statistic for the nested ridge
      perm_knn <- nestedcv.knn(folds = perm_folds, regs = perm_regs, labs = sub_labs) ### compute (permuted) test statistic for the nested knn
      matrix(c(perm_ridge, perm_knn), nrow = 2) ### return permuted test statistics for both tests
    }
    res[i, 2] <- mean(ridge_stat*(1-1e-14) <= c(Inf, perm_mat[1, , drop = TRUE])) ### compute emperical p-value for nested ridge
    res[i, 3] <- mean(knn_stat*(1-1e-14) <= c(Inf, perm_mat[2, , drop = TRUE])) ### compute emperical p-value for nested knn
  }
  return(res)
}
```

```{r}
ggplot(data[["circles"]][c(1:20, 50001:50020), ], aes(x = x1, y = x2, colour = y)) + geom_point()

ExtDataSim <- function(data, n_reps, sampsize, n = 50000, ...){
  indx <- seq(1, n)
  sub_data <- rbind(data[sample(indx, sampsize*n_reps/2), ], data[sample(indx, sampsize*n_reps/2) + n, ]) 
  out <- SimExp(n_reps = n_reps, data = sub_data, ...)
  out <- EmpericalPower(out)
  return(out)
}
CS_samp40 <- ExtDataSim(data[["circles"]], sampsize = 40, pckgs = pckgs, n_reps = 100)
```

```{r}
ggplot(data[["linear"]][c(1:20, 50001:50020), ], aes(x = x1, y = x2, colour = y)) + geom_point()

LS_samp40 <- ExtDataSim(data[["linear"]], sampsize = 40, pckgs = pckgs, n_reps = 100)
```

```{r}
png("checkerboardplot.png")
ggplot(CheckerSamp(p = 2, n = 5, n_clusts = 3, c = 1), aes(x = x1, y = x2, colour = y)) + geom_point()
dev.off()
```

```{r}
CheckerSim <- function(n_reps, n, n_clusts, ...){
  indx_args <- c(length(n) > 1, length(n_clusts) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("n", "n_clusts")[indx_args]
  params <- cbind(n, n_clusts) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    sampsize <- params[[i, "n_clusts"]]^2 * params[[i, "n"]]
    indx <- as.vector(sapply(1:n_reps, function(x, sampsize) rep(x, sampsize), sampsize = sampsize))
    data <- lapply(1:n_reps, FUN = function(x, n, n_clusts) CheckerSamp(n = n, n_clusts = n_clusts),
                   n = params[[i, "n"]], n_clusts = params[[i, "n_clusts"]])
    data <- as_tibble(do.call(rbind, data))
    tmp <- SimExp(n_reps = n_reps, data = data, indx = indx, ...)
    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  #if(sum(as.numeric(indx_args)) > 0){
  #  out <- data.frame(out, params[, var_name])
  #  colnames(out)[ncol(out)] <- var_name
  #  out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
  #  out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point()
  #}
  return(out)
}
```

```{r}
CheckerSim <- function(n_reps, n, n_clusts, ...){
  indx_args <- c(length(n) > 1, length(n_clusts) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("n", "n_clusts")[indx_args]
  params <- cbind(n, n_clusts) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  start <- Sys.time()
  for (i in 1:nrow(params)){
    cat("Start element", i, "\n")
    res <- foreach (j = 1:n_reps, .combine = "rbind", .export = pckgs, .packages = c("doParallel", "globaltest")) %dopar% {
      data <- CheckerSamp(n = params[[i, "n"]], n_clusts = params[[i, "n_clusts"]])
      tmp <- SimExp(n_reps = 1, data = data, indx = NA, n_perms = n_perms, ...)
    }
    out[[i]] <- EmpericalPower(res)
    end <- Sys.time()
    cat("Finished element", i, "\n")
    print(end-start)
    start <- end  
  }
  out <- do.call(rbind, out)
  #if(sum(as.numeric(indx_args)) > 0){
  #  out <- data.frame(out, params[, var_name])
  #  colnames(out)[ncol(out)] <- var_name
  #  out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
  #  out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point()
  #}
  return(out)
}
```

```{r}
CBS_nclusts <- CheckerSim(n_reps = 100, n = 3, n_clusts = c(3, 5), pckgs = pckgs, force = TRUE)
```

```{r}
CBS_n <- CheckerSim(n_reps = 100, n = c(2, 5, 10), n_clusts = 3, pckgs = pckgs, force = TRUE)
```


```{r}
png("LDAplot.png")
ggplot(LDASamp(n_samples = 40, p = 2, effect = 25), aes(x = x1, y = x2, colour = y)) + geom_point()
dev.off()
```

```{r}
LDASim <- function(sampsize, n_reps, effect, p, pckgs, ...){
  indx_args <- c(length(p) > 1, length(effect) > 1, length(sampsize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("p", "effect", "sampsize")[indx_args]
  params <- cbind(p, effect, sampsize) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  for (i in 1:nrow(params)){
    data <- as_tibble(LDASamp(n_samples = params[i, "sampsize"] * n_reps, p = params[i, "p"], effect = params[i, "effect"]))
    tmp <- SimExp(n_reps = n_reps, data = data, pckgs = pckgs, ...)
    out[[i]] <- EmpericalPower(tmp)
  }
  out <- do.call(rbind, out)
  #if(sum(as.numeric(indx_args)) > 0){
  #  out <- data.frame(out, params[, var_name])
  #  colnames(out)[ncol(out)] <- var_name
  #  out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
  #  out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point()
  #}
  return(out)
}
```

```{r}
LDASim <- function(sampsize, n_reps, effect, p, pckgs, ...){
  indx_args <- c(length(p) > 1, length(effect) > 1, length(sampsize) > 1)
  if(sum(as.numeric(indx_args)) > 1) stop("Only one parameter can have multiple values") ### only allow for one parameter to take on multiple values
  var_name <- c("p", "effect", "sampsize")[indx_args]
  params <- cbind(p, effect, sampsize) ### parameter space
  out <- vector(mode = "list", length = nrow(params))
  start <- Sys.time()
  for (i in 1:nrow(params)){
    cat("Start element", i, "\n")
    res <- foreach (j = 1:n_reps, .combine = "rbind", .export = pckgs, .packages = c("doParallel", "globaltest")) %dopar% {
      data <- LDASamp(n_samples = params[i, "sampsize"], p = params[i, "p"], effect = params[i, "effect"])
      tmp <- SimExp(n_reps = 1, data = data, indx = NA, n_perms = n_perms, ...)
    }
    out[[i]] <- EmpericalPower(res)
    end <- Sys.time()
    cat("Finished element", i, "\n")
    print(end-start)
    start <- end
  }
  out <- do.call(rbind, out)
  #if(sum(as.numeric(indx_args)) > 0){
  #  out <- data.frame(out, params[, var_name])
  #  colnames(out)[ncol(out)] <- var_name
  #  out <- pivot_longer(out, !last_col(), names_to = "method", values_to = "RF")
  #  out <- ggplot(data = out, aes(x = .data[[var_name]], y = RF, colour = method)) + geom_line(linetype = "dashed") + geom_point()
  #}
  return(out)
}
LDASim(sampsize = 40, n_reps = 100, effect = c(0.1 , 1, 5, 10), p = c(2), pckgs = pckgs)
```


```{r}
set.seed(1979418)
LDAS_p <- LDASim(sampsize = 40, n_reps = 100, effect = 25, p = c(2, 10, 25, 50, 100), pckgs = pckgs)
```

```{r}
LDAS_effect <- LDASim(sampsize = 40, n_reps = 100, effect = c(25, 20, 10, 1), p = 2, pckgs = pckgs)
```


```{r}
regs <- data[["circles"]][c(1:50, 50001:50050), c("x1", "x2")]
labs <- data[["circles"]][c(1:50, 50001:50050), c("y")]
folds <- create_folds(n_folds = 5, labs = labs)
```


### Weight experiment inversely weighted (variance) overall global test

```{r}
weights_gt <- function(regs, labs){
  n <- nrow(regs) ### compute number of observations
  dist_mat <- comp_dist(regs) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering matrix
  P <- vector(mode = "list", length = n)
  weights <- numeric(n)
  for(i in 1:n){ ### for all 1, ..., k neighbours
    P[[i]] <- ifelse(ord_mat > (n - i), 1, 0) ### compute partition matrix
    weights[i] <- InvPropWeight(P[[i]], labs) ### weight according to inverse of variance of partition matrix
  }
  return(weights)
}

WeightSimExp <- function(data, n_reps, pckgs, indx = NA, n_perms = 100, ...){
  labs <- data[, "y"] ### extract labels
  regs <- data[, !names(data) %in% "y"] ### extract predictors
  if(all(is.na(indx))){ ### if no weights specified
    indx <- create_folds(n_folds = n_reps, labs = labs, ...) ### compute folds equal to the number of replications
  }
  res <- matrix(data = NA, nrow = max(indx), ncol = max(table(indx))) ### initialize output matrix
  
  for(i in 1:max(indx)){ ### for each folds
    sub_regs <- regs[indx == i,] ### select regressor subset
    sub_labs <- labs[indx == i,] ### select label subset
    res[i, ] <- weights_gt(regs = sub_regs, labs = sub_labs) 
  }
  return(res)
}

ExtDataWeightSim <- function(data, n_reps, sampsize, n = 50000, ...){
  indx <- seq(1, n)
  sub_data <- rbind(data[sample(indx, sampsize*n_reps/2), ], data[sample(indx, sampsize*n_reps/2) + n, ]) 
  out <- WeightSimExp(n_reps = n_reps, data = sub_data, ...)
  return(out)
}
CS_weights40 <- ExtDataWeightSim(data[["circles"]], sampsize = 40, n_reps = 100)
LS_weights40 <- ExtDataWeightSim(data[["linear"]], sampsize = 40, n_reps = 100)
plot(log(apply(CS_weights40, 2, mean)))
plot(log(apply(LS_weights40, 2, mean)))
```

```{r}
CheckerWeightSim <- function(n_reps, n, n_clusts, ...){
  sampsize <- n_clusts^2 * n
  indx <- as.vector(sapply(1:n_reps, function(x, sampsize) rep(x, sampsize), sampsize = sampsize))
  data <- lapply(1:n_reps, FUN = function(x, n, n_clusts) CheckerSamp(n = n, n_clusts = n_clusts),
                   n = n, n_clusts = n_clusts)
  data <- as_tibble(do.call(rbind, data))
  out <- WeightSimExp(n_reps = n_reps, data = data, indx = indx, ...)
  
  return(out)
}
CBS_weight <- CheckerWeightSim(n_reps = 100, n = 3, n_clusts = 3, force = TRUE)
plot(log(apply(LDAS_weight, 2, mean)))
```

```{r}
LDAWeightSim <- function(sampsize, n_reps, effect, p, ...){
  data <- as_tibble(LDASamp(n_samples = sampsize * n_reps, p = p, effect = effect))
  out <- WeightSimExp(n_reps = n_reps, data = data, ...)
  return(out)
}
LDAS_weight <- LDAWeightSim(sampsize = 40, n_reps = 100, effect = 25, p = 2)
plot(log(apply(LDAS_weight, 2, mean)))
```
```{r}
comp_dist <- function(X){
  n <- nrow(X)
  nom_indx <- unlist(lapply(X, function(x) as.logical(is.factor(x) + is.character(x))))
  dist_nom <- dist_num <- matrix(0, nrow = n, ncol = n)
  
  if(ncol(X) - sum(as.numeric(nom_indx)) > 0){
    X_num <- scale(X[, !nom_indx])
    dist_num <- as.matrix(dist(X_num, diag = TRUE, upper = TRUE))^2
  }
  
  if(sum(as.numeric(nom_indx)) > 0){
    X_nom <- X[, nom_indx]
    for(i in 1:(n - 1)){
      for(j in (i + 1):n){
        dist_nom[i, j] <- sum(X_nom[i,] != X_nom[j,])
      }
    }
    dist_nom[lower.tri(dist_nom)] <- dist_nom[upper.tri(dist_nom)]
  }
  
  return(sqrt(dist_num + dist_nom))
} 
comp_dist(tmp)
```

```{r}
all.tests <- function(regs, labs, pckgs, n_perms = 100, ...){
  res <- rep(NA, 7)
  folds <- create_folds(n_folds = 5, labs = labs, ...) ### create folds for functions that require cross validation
  res[1] <- linear.gt(regs = regs, labs = labs) ### compute p-value of the linear global test
  ridge_stat <- nestedcv.ridge(folds = folds, regs = regs, labs = labs) ### compute test statistic for the nested ridge
  knn_stat <- nestedcv.knn(folds = folds, regs = regs, labs = labs) ### compute test statistic for the nested knn
  res[4] <- prop.knn_gt(regs = regs, labs = labs) ### compute p-value for the global test on the partition matrix based on the label proportion
  res[5] <- pval.knn_gt(regs = regs, labs = labs, ...) ### compute p-value for the global test based on the value of k which has the smallest p-value in the training set
  res[c(6, 7)] <- overall.gt(regs = regs, labs = labs, invweighted = TRUE) ### compute unweighted and inversely weighted overall gloval test
    
  perm_mat <- foreach(j = 1:n_perms, .combine = "cbind", .export = pckgs) %dopar% { ### for n_perms replications
    perm_indx <- sample(nrow(labs)) ### permutation index
    perm_regs <- regs[perm_indx, ] ### permute regressors
    perm_folds <- create_folds(n_folds = 5, labs = labs, ...) ### compute folds
    perm_ridge <- nestedcv.ridge(folds = perm_folds, regs = perm_regs, labs = labs) ### compute (permuted) test statistic for the nested ridge
    perm_knn <- nestedcv.knn(folds = perm_folds, regs = perm_regs, labs = labs) ### compute (permuted) test statistic for the nested knn
    matrix(c(perm_ridge, perm_knn), nrow = 2) ### return permuted test statistics for both tests
    }
  res[2] <- 1- mean(ridge_stat > perm_mat[1, ]) ### compute emperical p-value for nested ridge
  res[3] <- 1- mean(knn_stat > perm_mat[2, ]) ### compute emperical p-value for nested knn
  names(res) <- c("linear.gt", "nestedcv.ridge", "nestedcv.knn", "prop.knn_gt", "pval.knn_gt", "overall.gt", "invoverall.gt") ### assign names to the output
  return(res)
}
all.tests(regs = regs, labs = labs, pckgs = pckgs, n_perms = 10)
```

