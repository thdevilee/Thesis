---
title: "KNN simulation synthetic data"
author: "Thomas Devilee"
date: "06/04/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load data and packages
```{r}
library(parallel)
library(doParallel)
library(foreach)
numCores <- detectCores()
registerDoParallel(numCores)
library(readxl)
library(class)
library(globaltest)
library(ggplot2)
library(glmnet)
library(dplyr)
library(MASS)
library(gridExtra)
set.seed(1979418)

### function to read excel files in the current directory in the format "sim_X.xlsx"
ReadData <- function(names){
  out <- vector(mode = "list", length = length(names)) ### initialize empty list with length equal to the number of datasets to be read (names)
  names(out) <- names ### assign list names
  for(i in 1:length(names)){ ### for all datasets to be read
    name <- paste0("sim_", names[i], ".xlsx")
    data <- read_excel(name) ### read excel files
    data <- data[order(data[["y"]]), ] ### order data based on y (label) value (small to big)
    data[["y"]] <- ifelse(data[["y"]] == 0, FALSE, TRUE) ### replace label values with FALSE if 0 and TRUE if 0
    out[[i]] <- data ### save this modified file to the list
  }
  return(out)
}
```

```{r}
data <- ReadData(c("linear", "moons", "circles"))
```

```{r}
### function to create folds implicitly requires the group size per class has to be equal
### if balanced is true (works only for two classes), the labels have to be sorted (low to high) 
create_folds <- function(n_folds, labs, balanced = TRUE){
  if(balanced){
    if (any(order(as.numeric(labs[["y"]])) != seq(1, nrow(labs)))) stop("Data (labels) is not sorted") ### checks if the above requirments are met
    reps1 <- (nrow(labs) - sum(as.numeric(labs[["y"]])))/n_folds
    reps2 <- sum(as.numeric(labs[["y"]]))/n_folds
    if (!is.int(reps1) | !is.int(reps2)) stop("Cannot balance folds")
    folds1 <- rep(seq(1, n_folds), reps1) ### create n fold indexes for group 1
    folds2 <- rep(seq(1, n_folds), reps2) ### create n fold indexes for group 2
    folds <- c(sample(folds1), sample(folds2)) ### randomly assign indexes to each observation in a balanced fashion
  } else{
    folds <- sample(rep(seq(1, n_folds), nrow(labs)/n_folds)) ### randomly assign folds if balanced is false
  }
  return(folds)
}

### function to compute knn ordering matrix for a given distance matrix
knn_mat <- function(dist_mat){
  n <- nrow(dist_mat) ### number of observations
  nn <- (n + 1) - t(apply(dist_mat, MARGIN = 1, FUN = rank)) ### ordering distance per observation
  return(nn)
}

rename_folds <- function(folds){
  digits <- sort(unique(folds))
  for (i in 1:length(digits)){
    folds[folds == digits[i]] <- i
  }
  return(folds)
}

InvPropWeight <- function(P, y){
  n <- nrow(P)
  I <- diag(n)
  H <- matrix(1, ncol = n, nrow = n)*(1/n)
  y <- as.matrix(y)
  XXT <- P %*% t(P) 
  dgXXT <- matrix(0, ncol = n, nrow = n)
  diag(dgXXT) <- diag(XXT)
  varP <- t(y) %*% (I - H) %*% (XXT - dgXXT) %*% (I - H) %*% y
  weight <- 1/varP
  if(is.infinite(weight))  weight <- 0
  return(weight)
}

XXT <- function(ord_mat, weights = NA){
  weighting <- TRUE
  k <- dim(ord_mat)[1]
  if(all(is.na(weights))){
    weighting <- FALSE
    weights <- rep(1, k)
  }
  if(weighting & k != length(weights)) stop("Incorrect dimensions weights")
  
  weights <- cumsum(rev(weights)^2)
  out <- matrix(data = NA, nrow = k, ncol = k)
  diag(out) <- sum(weights)
  for(i in 1:(k - 1)){
    for(j in (i + 1):k){
      out[i, j] <- sum(weights[pmin(ord_mat[i,], ord_mat[j,])])
    }
  }
  out[lower.tri(out)] <- t(out)[lower.tri(out)]
  return(out)
}

### function to compute p-values based on the partition matrix (for 1, ..., k neighbours and the overall test) for reps replications
power_knn <- function(data, reps){
  p_vals <- matrix(data = NA, nrow = reps, ncol = n) ### initialize empty matrix for p-values from global test 
  
  for (i in 1:reps){ ### for all replications
    X <- vector(mode = "list", length = n) ### initialize empty list of length n to accomodate all k partition matrices
    sub_data <- data[folds == i, ] ### select data in fold i
    sub_X <- as.matrix(sub_data[, !names(sub_data) %in% "y"])
    dist_mat <- as.matrix(dist(sub_X, diag = TRUE, upper = TRUE)) ### compute distance matrix
    ord_mat <- knn_mat(dist_mat) ### compute ordering mat
    for (j in 1:n){ ### for all 1, ..., k neighbours
      X[[j]] <- ifelse(ord_mat > (n - j), 1, 0) ### compute partition matrix and save in list
      p_vals[i, j] <- gt(y ~ 1, y ~ ., data = data.frame(X[[j]], y = sub_data["y"]))@result[1] ### compute gt statistic based on partition matrix
    }
  }
  return(p_vals) ### return a matrix with p-values with reps rows and n + 1 columns, where the last column contain p-values from the overall gt
}

is.int <- function(x) x%%1 == 0
```

```{r}
nestedcv.knn <- function(neighbours, folds, regs, labs){
  n_folds <- max(folds)
  res_outer <- numeric(n_folds)
  fold_id <- seq(1, n_folds)
  for(i in 1:n_folds){
    res_inner <- matrix(NA, nrow = n_folds - 1, ncol = length(neighbours))
    for(j in 1:(n_folds - 1)){
      for(k in 1:length(neighbours)){
        indx <- fold_id[fold_id != i] 
        tmp <- class::knn(regs[(folds %in% indx[-j]),], regs[(folds == indx[j]),], labs[(folds %in% indx[-j]), , drop = TRUE], k = neighbours[k])
        res_inner[j, k] <- mean(tmp != labs[folds == indx[j], , drop = TRUE])
      }
    }
    res_inner <- apply(res_inner, MARGIN = 2, mean)
    preds <- class::knn(regs[folds != i,], regs[folds == i,], labs[folds != i, , drop = TRUE], k = neighbours[which.min(res_inner)])
    res_outer[i] <- mean(preds == labs[folds == i, , drop = TRUE])
  }
  return(mean(res_outer))
}

nestedcv.ridge <- function(folds, regs, labs){
  n_folds <- max(folds)
  res_outer <- numeric(n_folds)
  for(i in 1:n_folds){
    log_indx <- folds != i
    regs_sub <- as.matrix(regs[log_indx, ])
    labs_sub <- labs[log_indx, , drop = TRUE]
    folds_sub <- rename_folds(folds[log_indx])
    res_cv <- glmnet::cv.glmnet(x = regs_sub, y = labs_sub, type.measure = "mse", foldid = folds_sub, alpha = 0)
    preds <- predict(res_cv, as.matrix(regs[folds == i,]), s = "lambda.min") >= 0.5
    res_outer[i] <- mean(preds == labs[folds == i, , drop = TRUE])
  }
  return(mean(res_outer))
}

linear.gt <- function(regs, labs){
  res <- gt(y~1, y~., data = data.frame(regs, y = labs))
  return(res@result[1])
}

```

```{r}
### is double dipping?
prop.knn_gt <- function(regs, labs){
  prop <- mean(labs[["y"]])
  prop <- min(prop, 1 - prop)
  dist_mat <- as.matrix(dist(regs, diag = TRUE, upper = TRUE)) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering mat
  P <- ifelse(ord_mat > nrow(regs) - prop*nrow(regs), 1, 0) ### compute partition matrix
  res <- gt(y ~ 1, y ~ ., data = cbind(P, labs))@result[1] ### compute gt statistic based on partition matrix
  return(res)
}


pval.knn_gt <- function(regs, labs){
  i <- 1
  folds <- create_folds(n_folds = 2, labs = labs)
  n_train <- sum(folds != i)
  dist_mat <- as.matrix(dist(regs[folds != i, ], diag = TRUE, upper = TRUE)) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat) ### compute ordering mat
  p_vals <- numeric(n_train)
  for (j in 1:n_train){ ### for all 1, ..., k neighbours
    P <- ifelse(ord_mat > (n_train - j), 1, 0) ### compute partition matrix and save in list
    p_vals[j] <- log(globaltest::gt(y ~ 1, y ~ ., data = cbind(P, labs[folds != i, ]))@result[1]) ### compute gt statistic based on partition matrix
    }
    optimal_k <- which.min(p_vals)
    n_test <- sum(folds == i)
    dist_mat <- as.matrix(dist(regs[folds == i, ], diag = TRUE, upper = TRUE)) ### compute distance matrix
    ord_mat <- knn_mat(dist_mat) ### compute ordering mat
    P <- ifelse(ord_mat > (n_test - optimal_k), 1, 0)
    res <- gt(y ~ 1, y ~ ., data = cbind(P, labs[folds == i, ]))@result[1]
  return(res)
}
pval.knn_gt(regs, labs)

overall.gt <- function(regs, labs, invweighted = FALSE){
  n <- nrow(regs)
  dist_mat <- as.matrix(dist(regs, diag = TRUE, upper = TRUE)) ### compute distance matrix
  ord_mat <- knn_mat(dist_mat)
  weights <- numeric(n)
  if (invweighted){ ### for all 1, ..., k neighbours
    for(i in 1:n){
      P <- ifelse(ord_mat > (n - i), 1, 0)
      weights[i] <- InvPropWeight(P, labs)
      }
  }
  return(weights)
  X <- t(chol(XXT(ord_mat = ord_mat)))
  res <- globaltest::gt(y ~ 1, y ~ ., data = data.frame(X, y = labs))@result[1]
  if(invweighted){
    X_iw <- t(chol(XXT(ord_mat = ord_mat, weights = weights)))
    res <- cbind(res, globaltest::gt(y ~ 1, y ~ ., data = data.frame(X_iw, y = labs))@result[1])
  }
  return(res)
}

tmp2 <- overall.gt(regs, labs, invweighted = TRUE)

```

```{r}
pckgs <- c("create_folds", "linear.gt", "nestedcv.ridge", "nestedcv.knn", "prop.knn_gt", "pval.knn_gt", "rename_folds", "knn_mat", "is.int", "gt")
SimExp <- function(n_reps, n_perms, data, pckgs){
  labs <- data[, "y"]
  regs <- data[, !names(data) %in% "y"]
  indx <- create_folds(n_folds = n_reps, labs = labs, balanced = TRUE)
  res <- matrix(data = NA, nrow = n_reps, ncol = 6)
  names(res) <- c("linear.gt", "nestedcv.ridge", "nestedcv.knn", "prop.knn_gt", "pval.knn_gt")
  
  for(i in 1:max(indx)){
    print(i)
    sub_regs <- regs[indx == i,]
    sub_labs <- labs[indx == i,]
    folds <- create_folds(n_folds = 5, labs = sub_labs, balanced = TRUE)
    res[i, 1] <- linear.gt(regs = sub_regs, labs = sub_labs)
    ridge_stat <- nestedcv.ridge(folds = folds, regs = sub_regs, labs = sub_labs)
    knn_stat <- nestedcv.knn(neighbours = c(5, 15), folds = folds, regs = sub_regs, labs = sub_labs)
    res[i, 4] <- prop.knn_gt(regs = sub_regs, labs = sub_labs)
    res[i, 5] <- pval.knn_gt(regs = sub_regs, labs = sub_labs)
    res[i, 6] <- overall.gt(regs = sub_regs, labs = sub_labs)
    
    perm_mat <- foreach(j = 1:n_perms, .combine = "cbind", .export = pckgs) %dopar% {
      perm_indx <- sample(nrow(sub_labs))
      perm_regs <- sub_regs[perm_indx, ]
      perm_folds <- create_folds(n_folds = 5, labs = sub_labs, balanced = TRUE)
      perm_ridge <- nestedcv.ridge(folds = perm_folds, regs = perm_regs, labs = sub_labs)
      perm_knn <- nestedcv.knn(neighbours = c(5, 15), folds = perm_folds, regs = perm_regs, labs = sub_labs)
      matrix(c(perm_ridge, perm_knn), nrow = 2)
    }
    res[i, 2] <- 1- mean(ridge_stat >= perm_mat[1, ])
    res[i, 3] <- 1- mean(knn_stat >= perm_mat[2, ])
  }
  return(res)
}
tmp <- SimExp(n_reps = 100, n_perms = 100, data = data[["circles"]][c(1:2000, 50001:52000), ], pckgs = pckgs)
```
```{r}
EmpericalPower <- function(data){
  out <- apply(data, 2, function(x) mean(x < 0.05))
  return(out)
}
EmpericalPower(tmp)
```



```{r}
regs <- data[["circles"]][c(1:50, 50001:50050), c("x1", "x2")]
labs <- data[["circles"]][c(1:50, 50001:50050), c("y")]
folds <- create_folds(n_folds = 2, labs = labs)
n <- nrow(regs)
dist_mat <- as.matrix(dist(regs, diag = TRUE, upper = TRUE)) ### compute distance matrix
ord_mat <- knn_mat(dist_mat)
P <- P_iw <- vector(mode = "list", length = n)
for (j in 1:n){ ### for all 1, ..., k neighbours
    P[[j]] <- ifelse(ord_mat > (n - j), 1, 0)
}
P_enh <- do.call(cbind, P)
res <- globaltest::gt(y ~ 1, y ~ ., data = data.frame(P_enh, y = labs))@result[1]
res


xxt <- XXT(ord_mat)
tmp <- t(chol(xxt))
globaltest::gt(y ~ 1, y ~ ., data = data.frame(tmp, y = labs))@result[1]
```

```{r}
tmp <- matrix(rnorm(100), 10, 10)
tmp <- data.frame(tmp, y = sample(c(0, 1), size = 10, replace = TRUE))
# get null and alternative
null <- .getNull(y ~ 1, tmp, 10, "linear")
alternative <- .getAlternative(y ~ ., tmp, 10)

.getAlternative <- function(alternative, data, n) {

  # coerce alternative into a matrix
  if (is.data.frame(alternative)) {
    if (all(sapply(alternative, is.numeric))) {
      alternative <- as.matrix(alternative)
    } else {
      stop("argument \"alternative\" could not be coerced into a matrix")
    }
  }
  if (is.vector(alternative)) {
    if (is.numeric(alternative)) {
      alternative <- as.matrix(alternative)
      colnames(alternative) <- "x"
    } else {
      stop("argument \"alternative\" could not be coerced into a matrix")
    }
  }
  # transpose if desired
  if (gt.options()$transpose && is.matrix(alternative))
    alternative <- t(alternative)
  if (is(alternative, "ExpressionSet")) {
    alternative <- t(exprs(alternative))
  }
  if (is(alternative, "formula")) {

    # keep NAs
    old.na.action <- options()$na.action  
    options(na.action="na.pass")

    # make appropriate contrasts
    mframe <- model.frame(alternative, data=data)
    factors <- names(mframe)[sapply(mframe, is.factor)]
    contrs <- lapply(factors, function(fac) {
      levs <- levels(mframe[[fac]])
      k <- length(levs)
      if (is.ordered(mframe[[fac]])) {
        contr <- matrix(0,k,k)
        contr[lower.tri(contr,diag=TRUE)] <- 1
      } else {
        contr <- diag(k)
      }
      rownames(contr) <- colnames(contr) <- levs                     
      contr 
    })
    names(contrs) <- factors
                             
    # make the design matrix
    alternative <- terms(alternative, data=data)
    if (length(attr(alternative, "term.labels")) == 0)
      stop("empty alternative")
    attr(alternative, "intercept") <- 1
    alternative <- model.matrix(alternative, contrasts.arg=contrs, data=data)
    alternative <- alternative[,colnames(alternative) != "(Intercept)",drop=FALSE]    # ugly, but I've found no other way
    
    # restore default
    options(na.action = old.na.action)
  }

  #check dimensions and names
  if (nrow(alternative) != n) {
    stop("the length of \"response\" (",n, ") does not match the row count of \"alternative\" (", nrow(alternative), ")")
  }
  if (is.null(colnames(alternative)))
    stop("colnames missing in alternative design matrix")

  alternative
}

.getNull <- function(null, data, n, model) {

  # coerce null into a matrix and find the offset term
  offset <- NULL
  if (is.data.frame(null) || is.vector(null)) {
    if (all(sapply(null, is.numeric))) {
      null <- as.matrix(null)
    } else {
      stop("argument \"null\" could not be coerced into a matrix")
    }
  }
  if (is(null, "formula")) {
    if (is.null(data)) {
      tnull <- terms(null)
      # prevent problems for input ~1 or ~0:
      if ((attr(tnull, "response") == 0) && (length(attr(tnull, "term.labels")) == 0)
          && (length(attr(tnull, "offset")) == 0)) {
        if (attr(tnull, "intercept") == 1)
          tnull <- terms(numeric(n) ~ 1)
        else
          tnull <- terms(numeric(n) ~ 0)
      }
      offset <- model.offset(model.frame(tnull))
    } else {
      offset <- model.offset(model.frame(null, data=data))
      tnull <- terms(null, data=data)
    }
    data <- model.frame(tnull, data, drop.unused.levels = TRUE)
    null <- model.matrix(tnull, data)
 
    # suppress intercept if necessary (can this be done more elegantly?)
    if (model == "cox") null <- null[,colnames(null) != "(Intercept)",drop=FALSE]
  }

  # check dimensions
  if (nrow(null) != n) {
    stop("the length of \"response\" (",n, ") does not match the row count of \"null\" (", nrow(null), ")")
  }

  list(null = null, offset = offset)
}
```

```{r}
Z <- null
X <- alternative
Y <- response
m <- ncol(Z)
n <- nrow(Z)
form <- formula(.makeFormula(m>0, !is.null(NULL)))
Y <- residuals(lm(form))
sumYY <- sum(Y*Y)
X <- X - Z %*% solve(crossprod(Z), crossprod(Z, X))
# set columns numerically zero to exactly zero
csm <- colSums(X*X)
X[,csm < max(csm)*1e-14] <- 0
norm.const <- sum(X * X) / 100
xy <- crossprod(X, Y)
S <- sum(xy * xy) / sumYY
if (sumYY == 0) S <- 0
lams <- eigen(crossprod(X), symmetric = TRUE, only.values=TRUE)$values
if (length(lams) < n) lams <- c(lams, numeric(n-length(lams)))
lams[1:(n-m)] <- lams[1:(n-m)] - S
# term needed for mean and variance of S for z-score
tr.term <- crossprod(X)
var.num <- 2*sum(tr.term*tr.term)
# mean and variance of S for z-score
# use series approximation as given in Paolella (2003) 319:
mu.num <- sum(lams) + (n-m)*S
mu.den <- n-m
var.den <- 2*(n-m)
cov.term <- 2*mu.num
ES <- (mu.num/mu.den) * (1 - cov.term/(mu.num*mu.den) + var.den/(mu.den^2))
VarS <- (mu.num^2/mu.den^2) * (var.num/(mu.num^2)  + var.den/(mu.den^2) - 2*cov.term/(mu.num*mu.den))
c(S = S/norm.const, ES = ES/norm.const, sdS = sqrt(VarS)/norm.const)

.makeFormula <- function(has.null, has.offset) {
  form <- "response ~ 0"
  if (has.null) form <- paste(form, "+Z")
  if (has.offset) form <- paste(form, "+offset(offset)")
  form
}
```

```{r}
gt1 <- function(response, alternative, null, data, test.value,    
            model = c("linear", "logistic", "cox", "poisson", "multinomial"), levels,
            directional = FALSE, standardize = FALSE, permutations = 0, 
            subsets, weights, alias, x = FALSE, trace) {
  
  # store the call
  call <- match.call()
  
  # avoid conflict between "levels" input and "levels" function
  if (missing(levels)) levels <- NULL
                       
  # data default
  if (missing(data)) {
    if ((!missing(alternative)) && (is(alternative, "ExpressionSet"))) {
      data <- pData(alternative)
    } else
      data <- NULL
  }
  if (is.matrix(data))  
    data <- data.frame(data)

  # evaluate response, which may be one of the colnames of data
  response <- eval(call$response, data, parent.frame())

  # settle null, alternative and response if response is a formula
  if (missing(null) || is.null(null)) {
    if ((!missing(alternative)) && is(response, "formula"))
      null <- response
    else
      null <- ~1
  } 
  if (missing(alternative))
    if (is(response, "formula"))
      alternative <- response
    else
      stop("argument \"alternative\" is missing, with no default")  
  if (is(response, "formula")) {
    name.response <-  deparse(eval(response)[[2]])
    response <- eval(attr(terms(response, data=data), "variables"), data, environment(response))[[attr(terms(response, data=data), "response")]]
  } else {
    name.response <- deparse(call$response)
  }
  
  # remove redundant levels from factor response
  # and coerce response to factor in case of levels input
  if (is.factor(response) || !is.null(levels))
    response <- factor(response) 
                                     
  # get the model
  if (missing(model)) {
    if(is(response, "Surv")) 
      model <- "cox"
    else if ((is.factor(response) && length(levels(response)) <= 2) || is.logical(response)) 
      model <- "logistic"
    else if (is.factor(response) && length(levels(response)) > 2)
      model <- "multinomial"
  }
  model <- match.arg(tolower(model), c("linear", "logistic", "cox", "poisson", "multinomial"))

  # if multinomial, coerce to factor and remove redundant level
  if (model=="multinomial" && !is.factor(response))
      response <- factor(response)
  
  # if multinomial, coerce to logistic if possible
  if (model=="multinomial" && nlevels(response)==2)
    model <- "logistic"
  
  # find the sample size
  if (model == "cox") {
    if (attr(response, "type") %in% c("right", "counting"))
      n <- nrow(response)
    else
      stop("survival data of type", attr(response, "type"), "not supported")
  } else {
    n <- length(response)
  }
                


  
  # remove terms from alternative that are also in null
  if (is(null, "formula") && is(alternative, "formula") && 
      identical(environment(null), environment(alternative))) {
    dup <- attr(terms(alternative, data=data), "term.labels") %in% attr(terms(null, data=data), "term.labels")
    if (all(dup)) stop("all covariates in alternative also in null")  
    if (any(dup)) 
      alternative <- formula(terms(alternative,data=data)[!dup])
  }
  
  
  # print a warning, when strata appear in alternative that do not appear in null, remove them from alternative
  if (is(alternative, "formula")) {
    if (length(attr(terms(alternative, specials = "strata", data=data), "specials")$strata) > 0) {
      altterms <- terms(alternative, specials = "strata", data=data)
      strata <- untangle.specials(altterms, "strata", 1)
      strata.nrs <- strata$terms
      alternative <- formula(altterms[-strata.nrs])
      warning("there are strata in alternative, which do no appear in null. strata only appearing in alternative are ignored")
      if (length(attr(terms(alternative, data=data), "term.labels")) == 0)
        stop("all covariates in alternative also in null")
    }
  }
  
  
  # extract strata out of null  
  if (is(null, "formula")) {
    nullterms <- terms(null, specials = "strata", data=data)
    if (length(attr(nullterms, "specials")$strata) > 0) {
      if (model == "cox") {
        strata <- untangle.specials(nullterms, "strata", 1)
        strata.nrs <- strata$terms
        strata.nrs2 <- attr(nullterms, "specials")$strata
        if (missing(data)) 
          strata <- strata(eval(attr(nullterms, "variables"), 
                                environment(nullterms))[strata.nrs2], shortlabel = TRUE)
        else
          strata <- strata(eval(attr(nullterms, 
                                        "variables"), data, environment(nullterms))[strata.nrs2], 
                              shortlabel = TRUE)
        null <- formula(nullterms[-strata.nrs])
      } 
      else 
        stop("strata only implemented for Cox model")
    }
    else 
      strata <- NULL
  }
  

  # get null and alternative
  null <- .getNull(null, data, n, model)
  alternative <- .getAlternative(alternative, data, n)

  # Adjust input due to levels argument
  if ((!is.null(levels)) && is.factor(response)) {
    if (!all(levels %in% levels(response)))
      stop("argument \"levels\" does not match levels(response)")
    if (length(levels) > 1) {
      select <- response %in% levels
      response <- factor(response[select], levels=levels)
      alternative <- alternative[select,,drop=FALSE]
      null$null <- null$null[select,, drop=FALSE]
      if (!is.null(null$offset)) 
        null$offset <- null$offset[select]
      if (length(levels) == 2)
        model <- "logistic"
    } else {
      response <- factor(response == levels)
      levels(response) <- c("other", levels)
      model <- "logistic"
    }
  }

  # prepare legends for plots later
  legend <- list()
  if (model == "logistic") {
    if (is.factor(response)) {
      legend$cov <- paste("assoc. with", name.response, "=", rev(levels(response)))
      legend$subj <- paste(name.response, "=", rev(levels(response)))
    } else {
      legend$cov <- paste("assoc. with", name.response, "=", 1:0)
      legend$subj <- paste(name.response, "=", 1:0)
    }
  } else if (model == "multinomial") {
    legend$cov <- paste("assoc. with", name.response, "=", levels(response))
    legend$subj <- paste(name.response, "=", levels(response))
  } else if (model %in% c("linear", "poisson")) {
    legend$cov <- paste(c("pos. assoc. with", "neg. assoc. with"), name.response)
    legend$subj <- paste(c("pos. residual", "neg. residual"), name.response)
  } else { # model = "survival" 
    legend$cov <- c("pos. assoc. with survival", "neg. assoc. with survival")
    legend$subj <- c("late event or censored", "early event")
  }

  #subsets and weigths
  if (!missing(subsets) && !is.list(subsets))
    subsets <- list(subsets)
  many.subsets <- !missing(subsets)
  one.weight <- (!missing(weights)) && (!is.list(weights)) && (length(weights)==ncol(alternative)) && many.subsets
  many.weights <- (!missing(weights)) && (!one.weight)
  if (many.weights && !is.list(weights))
    weights <- list(weights)

  # if a test.value was specified, adjust the offset term
  # NOTE: test.value is interpreted relative to alternative BEFORE standardizaton and weighting
  if (!missing(test.value)) {
    if (length(test.value) == ncol(alternative))
      test.offset <- drop(alternative %*% test.value)
    else if ((length(subsets)==1) && (length(test.value) == length(subsets[[1]])))
      test.offset <- drop(alternative[,subsets[[1]], drop=FALSE] %*% test.value)
    else
      stop("the length of \"test.value\" (",length(test.value), ") does not match the the number of covariates in \"alternative\" (", ncol(alternative), ")")
    if (!is.null(null$offset))
      offset <- null$offset + test.offset
    else      
      offset <- test.offset
  } else
    offset <- null$offset   
  null <- null$null
  if (model == "multinomial" && !is.null(offset))
    stop("offset term and test.value not yet implemented for the multinomial model")
  return(alternative)
}

alternative <- gt1(y ~ 1, y ~. , data =tmp)
```

